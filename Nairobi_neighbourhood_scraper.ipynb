{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "###ENVIRONMENTAL SETUP"
      ],
      "metadata": {
        "id": "o-hBHAiPnaB3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install playwright\n",
        "!playwright install chromium\n",
        "!playwright install-deps chromium\n",
        "!pip install nest_asyncio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wpvL_PcPfUWO",
        "outputId": "732933ef-6a92-4950-fe63-6945e408bf55"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: playwright in /usr/local/lib/python3.12/dist-packages (1.58.0)\n",
            "Requirement already satisfied: pyee<14,>=13 in /usr/local/lib/python3.12/dist-packages (from playwright) (13.0.1)\n",
            "Requirement already satisfied: greenlet<4.0.0,>=3.1.1 in /usr/local/lib/python3.12/dist-packages (from playwright) (3.3.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from pyee<14,>=13->playwright) (4.15.0)\n",
            "Installing dependencies...\n",
            "Hit:1 https://cli.github.com/packages stable InRelease\n",
            "Hit:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:3 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "fonts-freefont-ttf is already the newest version (20120503-10build1).\n",
            "fonts-liberation is already the newest version (1:1.07.4-11).\n",
            "libatk-bridge2.0-0 is already the newest version (2.38.0-3).\n",
            "libatk1.0-0 is already the newest version (2.36.0-3build1).\n",
            "libatspi2.0-0 is already the newest version (2.44.0-3).\n",
            "libcairo2 is already the newest version (1.16.0-5ubuntu2).\n",
            "libfontconfig1 is already the newest version (2.13.1-4.2ubuntu5).\n",
            "libxcb1 is already the newest version (1.14-3ubuntu3).\n",
            "libxcomposite1 is already the newest version (1:0.4.5-1build2).\n",
            "libxdamage1 is already the newest version (1:1.1.5-2build2).\n",
            "libxext6 is already the newest version (2:1.3.4-1build1).\n",
            "libxfixes3 is already the newest version (1:6.0.0-1).\n",
            "libxkbcommon0 is already the newest version (1.4.0-1).\n",
            "libxrandr2 is already the newest version (2:1.5.2-1build1).\n",
            "xfonts-scalable is already the newest version (1:1.0.3-1.2ubuntu1).\n",
            "fonts-ipafont-gothic is already the newest version (00303-21ubuntu1).\n",
            "fonts-tlwg-loma-otf is already the newest version (1:0.7.3-1).\n",
            "fonts-unifont is already the newest version (1:14.0.01-1).\n",
            "fonts-wqy-zenhei is already the newest version (0.9.45-8).\n",
            "xfonts-cyrillic is already the newest version (1:1.0.5).\n",
            "fonts-noto-color-emoji is already the newest version (2.047-0ubuntu0.22.04.1).\n",
            "libasound2 is already the newest version (1.2.6.1-1ubuntu1.1).\n",
            "libasound2 set to manually installed.\n",
            "libcups2 is already the newest version (2.4.1op1-1ubuntu4.16).\n",
            "libdbus-1-3 is already the newest version (1.12.20-2ubuntu4.1).\n",
            "libdrm2 is already the newest version (2.4.113-2~ubuntu0.22.04.1).\n",
            "libfreetype6 is already the newest version (2.11.1+dfsg-1ubuntu0.3).\n",
            "libgbm1 is already the newest version (23.2.1-1ubuntu3.1~22.04.3).\n",
            "libglib2.0-0 is already the newest version (2.72.4-0ubuntu2.9).\n",
            "libnspr4 is already the newest version (2:4.35-0ubuntu0.22.04.1).\n",
            "libnss3 is already the newest version (2:3.98-0ubuntu0.22.04.2).\n",
            "libpango-1.0-0 is already the newest version (1.50.6+ds-2ubuntu1).\n",
            "libwayland-client0 is already the newest version (1.20.0-1ubuntu0.1).\n",
            "libx11-6 is already the newest version (2:1.7.5-1ubuntu0.3).\n",
            "xvfb is already the newest version (2:21.1.4-2ubuntu1.7~22.04.16).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 75 not upgraded.\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.12/dist-packages (1.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###SCRAPING"
      ],
      "metadata": {
        "id": "pC_kcDmQuedv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lQjtFSmEevA-",
        "outputId": "5d752fcd-88e7-4996-cfa4-d1fe00736dc7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing: KILIMANI\n",
            "   - Page 1: Found 23 items\n",
            "   - Page 2: Found 23 items\n",
            "   - Page 3: Found 23 items\n",
            "   - Page 4: Found 23 items\n",
            "   - Page 5: Found 23 items\n",
            "   - Page 6: Found 23 items\n",
            "   - Page 7: Found 23 items\n",
            "   - Page 8: Found 23 items\n",
            "Processing: KILELESHWA\n",
            "   - Page 1: Found 23 items\n",
            "   - Page 2: Found 23 items\n",
            "   - Page 3: Found 23 items\n",
            "   - Page 4: Found 23 items\n",
            "   - Page 5: Found 23 items\n",
            "   - Page 6: Found 23 items\n",
            "   - Page 7: Found 23 items\n",
            "   - Page 8: Found 23 items\n",
            "Processing: LAVINGTON\n",
            "   - Page 1: Found 23 items\n",
            "   - Page 2: Found 23 items\n",
            "   - Page 3: Found 23 items\n",
            "   - Page 4: Found 23 items\n",
            "   - Page 5: Found 23 items\n",
            "   - Page 6: Found 23 items\n",
            "   - Page 7: Found 23 items\n",
            "   - Page 8: Found 23 items\n",
            "Processing: KAREN\n",
            "   - Page 1: Found 23 items\n",
            "   - Page 2: Found 23 items\n",
            "   - Page 3: Found 23 items\n",
            "   - Page 4: Found 23 items\n",
            "   - Page 5: Found 23 items\n",
            "   - Page 6: Found 23 items\n",
            "   - Page 7: Found 23 items\n",
            "   - Page 8: Found 23 items\n",
            "Processing: WESTLANDS\n",
            "   - Page 1: Found 23 items\n",
            "   - Page 2: Found 23 items\n",
            "   - Page 3: Found 23 items\n",
            "   - Page 4: Found 23 items\n",
            "   - Page 5: Found 23 items\n",
            "   - Page 6: Found 23 items\n",
            "   - Page 7: Found 23 items\n",
            "   - Page 8: Found 23 items\n",
            "Processing: RUNDA\n",
            "   - Page 1: Found 22 items\n",
            "   - Page 2: Found 22 items\n",
            "   - Page 3: Found 22 items\n",
            "   - Page 4: Found 22 items\n",
            "   - Page 5: Found 22 items\n",
            "   - Page 6: Found 22 items\n",
            "   - Page 7: Found 22 items\n",
            "   - Page 8: Found 22 items\n",
            "Processing: MUTHAIGA\n",
            "   - Page 1: Found 23 items\n",
            "   - Page 2: Found 23 items\n",
            "   - Page 3: Found 23 items\n",
            "   - Page 4: Found 23 items\n",
            "   - Page 5: Found 23 items\n",
            "   - Page 6: Found 23 items\n",
            "   - Page 7: Found 23 items\n",
            "   - Page 8: Found 23 items\n",
            "Processing: SPRING VALLEY\n",
            "   - Page 1: Found 23 items\n",
            "   - Page 2: Found 23 items\n",
            "   - Page 3: Found 23 items\n",
            "   - Page 4: Found 23 items\n",
            "   - Page 5: Found 23 items\n",
            "   - Page 6: Found 23 items\n",
            "   - Page 7: Found 23 items\n",
            "   - Page 8: Found 23 items\n",
            "Processing: KITISURU\n",
            "   - Page 1: Found 23 items\n",
            "   - Page 2: Found 23 items\n",
            "   - Page 3: Found 23 items\n",
            "   - Page 4: Found 23 items\n",
            "   - Page 5: Found 23 items\n",
            "   - Page 6: Found 23 items\n",
            "   - Page 7: Found 23 items\n",
            "   - Page 8: Found 23 items\n",
            "Processing: NAIROBI WEST\n",
            "   - Page 1: Found 23 items\n",
            "   - Page 2: Found 23 items\n",
            "   - Page 3: Found 23 items\n",
            "   - Page 4: Found 23 items\n",
            "   - Page 5: Found 23 items\n",
            "   - Page 6: Found 23 items\n",
            "   - Page 7: Found 23 items\n",
            "   - Page 8: Found 23 items\n",
            "Processing: SOUTH B\n",
            "   - Page 1: Found 22 items\n",
            "   - Page 2: Found 22 items\n",
            "   - Page 3: Found 22 items\n",
            "   - Page 4: Found 22 items\n",
            "   - Page 5: Found 22 items\n",
            "   - Page 6: Found 22 items\n",
            "   - Page 7: Found 22 items\n",
            "   - Page 8: Found 22 items\n",
            "Processing: SOUTH C\n",
            "   - Page 1: Found 22 items\n",
            "   - Page 2: Found 22 items\n",
            "   - Page 3: Found 22 items\n",
            "   - Page 4: Found 22 items\n",
            "   - Page 5: Found 22 items\n",
            "   - Page 6: Found 22 items\n",
            "   - Page 7: Found 22 items\n",
            "   - Page 8: Found 22 items\n",
            "Processing: MADARAKA\n",
            "   - Page 1: Found 6 items\n",
            "Processing: NAIROBI SOUTH\n",
            "   - Page 1: Found 11 items\n",
            "Processing: PARKLANDS\n",
            "   - Page 1: Found 23 items\n",
            "   - Page 2: Found 23 items\n",
            "   - Page 3: Found 23 items\n",
            "   - Page 4: Found 23 items\n",
            "   - Page 5: Found 23 items\n",
            "   - Page 6: Found 23 items\n",
            "   - Page 7: Found 23 items\n",
            "   - Page 8: Found 23 items\n",
            "Processing: NGARA\n",
            "   - Page 1: Found 17 items\n",
            "   - Page 2: Found 17 items\n",
            "   - Page 3: Found 17 items\n",
            "   - Page 4: Found 17 items\n",
            "   - Page 5: Found 17 items\n",
            "   - Page 6: Found 17 items\n",
            "   - Page 7: Found 17 items\n",
            "   - Page 8: Found 17 items\n",
            "Processing: PANGANI\n",
            "   - Page 1: Found 3 items\n",
            "Processing: WOODLEY\n",
            "   - Page 1: Found 9 items\n",
            "Processing: MOUNTAIN VIEW\n",
            "   - Page 1: Found 6 items\n",
            "Processing: RUAKA\n",
            "   - Page 1: Found 22 items\n",
            "   - Page 2: Found 22 items\n",
            "   - Page 3: Found 22 items\n",
            "   - Page 4: Found 22 items\n",
            "   - Page 5: Found 22 items\n",
            "   - Page 6: Found 22 items\n",
            "   - Page 7: Found 22 items\n",
            "   - Page 8: Found 22 items\n",
            "Processing: ROYSAMBU\n",
            "   - Page 1: Found 23 items\n",
            "   - Page 2: Found 23 items\n",
            "   - Page 3: Found 23 items\n",
            "   - Page 4: Found 23 items\n",
            "   - Page 5: Found 23 items\n",
            "   - Page 6: Found 23 items\n",
            "   - Page 7: Found 23 items\n",
            "   - Page 8: Found 23 items\n",
            "Processing: KASARANI\n",
            "   - Page 1: Found 17 items\n",
            "   - Page 2: Found 17 items\n",
            "   - Page 3: Found 17 items\n",
            "   - Page 4: Found 17 items\n",
            "   - Page 5: Found 17 items\n",
            "   - Page 6: Found 17 items\n",
            "   - Page 7: Found 17 items\n",
            "   - Page 8: Found 17 items\n",
            "Processing: EMBAKASI\n",
            "   - Page 1: Found 23 items\n",
            "   - Page 2: Found 23 items\n",
            "   - Page 3: Found 23 items\n",
            "   - Page 4: Found 23 items\n",
            "   - Page 5: Found 23 items\n",
            "   - Page 6: Found 23 items\n",
            "   - Page 7: Found 23 items\n",
            "   - Page 8: Found 23 items\n",
            "Processing: IMARA DAIMA\n",
            "   - Page 1: Found 6 items\n",
            "Processing: NYAYO ESTATE\n",
            "   - Page 1: Found 8 items\n",
            "Processing: UTAWALA\n",
            "   - Page 1: Found 3 items\n",
            "Processing: CHOKAA\n",
            "   - Page 1: Found 3 items\n",
            "Processing: RUAI\n",
            "   - Page 1: Found 14 items\n",
            "Processing: GITHURAI\n",
            "   - Page 1: Found 5 items\n",
            "Processing: KIAMBU ROAD\n",
            "   - Page 1: Found 22 items\n",
            "   - Page 2: Found 22 items\n",
            "   - Page 3: Found 22 items\n",
            "   - Page 4: Found 22 items\n",
            "   - Page 5: Found 22 items\n",
            "   - Page 6: Found 22 items\n",
            "   - Page 7: Found 22 items\n",
            "   - Page 8: Found 22 items\n",
            "Processing: GARDEN ESTATE\n",
            "   - Page 1: Found 23 items\n",
            "   - Page 2: Found 23 items\n",
            "   - Page 3: Found 23 items\n",
            "   - Page 4: Found 23 items\n",
            "   - Page 5: Found 23 items\n",
            "   - Page 6: Found 23 items\n",
            "   - Page 7: Found 23 items\n",
            "   - Page 8: Found 23 items\n",
            "Processing: THIKA ROAD\n",
            "   - Page 1: Found 22 items\n",
            "   - Page 2: Found 22 items\n",
            "   - Page 3: Found 22 items\n",
            "   - Page 4: Found 22 items\n",
            "   - Page 5: Found 22 items\n",
            "   - Page 6: Found 22 items\n",
            "   - Page 7: Found 22 items\n",
            "   - Page 8: Found 22 items\n",
            "Processing: LOWER KABETE\n",
            "   - Page 1: Found 22 items\n",
            "   - Page 2: Found 22 items\n",
            "   - Page 3: Found 22 items\n",
            "   - Page 4: Found 22 items\n",
            "   - Page 5: Found 22 items\n",
            "   - Page 6: Found 22 items\n",
            "   - Page 7: Found 22 items\n",
            "   - Page 8: Found 22 items\n",
            "Processing: KAHAWA WEST\n",
            "   - Page 1: Found 11 items\n",
            "Processing: KAHAWA NORTH\n",
            "   - Page 1: Found 4 items\n",
            "Processing: RIRUTA\n",
            "   - Page 1: Found 23 items\n",
            "   - Page 2: Found 23 items\n",
            "   - Page 3: Found 23 items\n",
            "   - Page 4: Found 23 items\n",
            "   - Page 5: Found 23 items\n",
            "   - Page 6: Found 23 items\n",
            "   - Page 7: Found 23 items\n",
            "   - Page 8: Found 23 items\n",
            "Processing: RIRUTA SATELLITE\n",
            "   - Page 1: Found 8 items\n",
            "Processing: NAIROBI CENTRAL\n",
            "   - Page 1: Found 23 items\n",
            "   - Page 2: Found 23 items\n",
            "   - Page 3: Found 23 items\n",
            "   - Page 4: Found 23 items\n",
            "   - Page 5: Found 23 items\n",
            "   - Page 6: Found 23 items\n",
            "   - Page 7: Found 23 items\n",
            "   - Page 8: Found 23 items\n",
            "Processing: EASTLEIGH NORTH\n",
            "   - Page 1: Found 6 items\n",
            "Processing: EASTLEIGH SOUTH\n",
            "   - Page 1: Found 4 items\n",
            "Processing: AIRBASE\n",
            "   - Page 1: Found 4 items\n",
            "Processing: LANDI MAWE\n",
            "   - Page 1: Found 22 items\n",
            "   - Page 2: Found 22 items\n",
            "   - Page 3: Found 22 items\n",
            "   - Page 4: Found 22 items\n",
            "   - Page 5: Found 22 items\n",
            "   - Page 6: Found 22 items\n",
            "   - Page 7: Found 22 items\n",
            "   - Page 8: Found 22 items\n",
            "Processing: MAKADARA\n",
            "   - Page 1: Found 6 items\n",
            "Processing: KOMAROCK\n",
            "   - Page 1: Found 5 items\n",
            "Processing: NGANDO\n",
            "   - Page 1: Found 4 items\n",
            "Processing: UPPER SAVANNAH\n",
            "   - Page 1: Found 22 items\n",
            "   - Page 2: Found 22 items\n",
            "   - Page 3: Found 22 items\n",
            "   - Page 4: Found 22 items\n",
            "   - Page 5: Found 22 items\n",
            "   - Page 6: Found 22 items\n",
            "   - Page 7: Found 22 items\n",
            "   - Page 8: Found 22 items\n",
            "\n",
            "SCRAPE COMPLETE! Total Unique Properties: 382\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_74552bbd-4859-42fa-8915-ebed40b5d9e9\", \"raw_listings_20260220.csv\", 69564)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import asyncio, random, pandas as pd\n",
        "from datetime import datetime\n",
        "import nest_asyncio\n",
        "from playwright.async_api import async_playwright\n",
        "\n",
        "# Allows the scraper to run in a Jupyter/Colab environment\n",
        "nest_asyncio.apply()\n",
        "\n",
        "async def scrape_neighborhood(page, neighborhood):\n",
        "    \"\"\"Scans multiple pages of a neighborhood with error handling and slug optimization.\"\"\"\n",
        "    listings = []\n",
        "    slug = neighborhood.lower().replace(\" \", \"-\")\n",
        "\n",
        "    # Dual-URL pattern to catch all possible KPC listing structures\n",
        "    url_patterns = [\n",
        "        f\"https://kenyapropertycentre.com/for-sale/nairobi/{slug}\",\n",
        "        f\"https://kenyapropertycentre.com/for-sale/{slug}\"\n",
        "    ]\n",
        "\n",
        "    print(f\"Processing: {neighborhood.upper()}\")\n",
        "\n",
        "    success_found = False\n",
        "    for base_url in url_patterns:\n",
        "        if success_found: break\n",
        "\n",
        "        # scan up to 8 pages deep for high-density areas\n",
        "        for page_num in range(0, 8):\n",
        "            offset = page_num * 20\n",
        "            target_url = f\"{base_url}?limitstart={offset}\"\n",
        "\n",
        "            try:\n",
        "                await page.goto(target_url, wait_until=\"domcontentloaded\", timeout=30000)\n",
        "                await asyncio.sleep(random.uniform(1.5, 3.0))\n",
        "\n",
        "                cards = await page.query_selector_all(\".property-list-item, [itemprop='itemListElement']\")\n",
        "                if not cards:\n",
        "                    break\n",
        "\n",
        "                success_found = True\n",
        "\n",
        "                for card in cards:\n",
        "                    try:\n",
        "                        title_elem = await card.query_selector(\"h3, h4\")\n",
        "                        price_elem = await card.query_selector(\".price\")\n",
        "                        link_elem = await card.query_selector(\"a\")\n",
        "\n",
        "                        if title_elem and link_elem:\n",
        "                            title = (await title_elem.inner_text()).strip()\n",
        "                            price = (await price_elem.inner_text()).strip() if price_elem else \"N/A\"\n",
        "                            url = await link_elem.get_attribute(\"href\")\n",
        "                            if not url.startswith(\"http\"):\n",
        "                                url = \"https://kenyapropertycentre.com\" + url\n",
        "\n",
        "                            listings.append({\n",
        "                                \"source\": \"KPC\",\n",
        "                                \"neighborhood\": neighborhood,\n",
        "                                \"title\": title,\n",
        "                                \"price\": price,\n",
        "                                \"url\": url,\n",
        "                                \"scraped_at\": datetime.now().strftime(\"%Y-%m-%d\")\n",
        "                            })\n",
        "                    except: continue\n",
        "\n",
        "                print(f\"   - Page {page_num + 1}: Found {len(cards)} items\")\n",
        "                if len(cards) < 15: break\n",
        "            except Exception as e:\n",
        "                print(f\"   - Error on page {page_num + 1}: {str(e)[:50]}...\")\n",
        "                break\n",
        "\n",
        "    return listings\n",
        "\n",
        "async def run_master_scraper():\n",
        "\n",
        "    neighborhoods = [\n",
        "\n",
        "        \"Kilimani\", \"Kileleshwa\", \"Lavington\", \"Karen\", \"Westlands\", \"Runda\", \"Muthaiga\", \"Spring Valley\", \"Kitisuru\",\n",
        "\n",
        "\n",
        "        \"Nairobi West\", \"South B\", \"South C\", \"Madaraka\", \"Nairobi South\", \"Parklands\", \"Ngara\", \"Pangani\", \"Woodley\", \"Mountain View\",\n",
        "\n",
        "\n",
        "        \"Ruaka\", \"Roysambu\", \"Kasarani\", \"Embakasi\", \"Imara Daima\", \"Nyayo Estate\", \"Utawala\", \"Chokaa\", \"Ruai\", \"Githurai\",\n",
        "\n",
        "\n",
        "        \"Kiambu Road\", \"Garden Estate\", \"Thika Road\", \"Lower Kabete\", \"Kahawa West\", \"Kahawa North\", \"Riruta\", \"Riruta Satellite\",\n",
        "\n",
        "\n",
        "        \"Nairobi Central\", \"Eastleigh North\", \"Eastleigh South\", \"Airbase\", \"Landi Mawe\", \"Makadara\", \"Komarock\", \"Ngando\", \"Upper Savannah\"\n",
        "    ]\n",
        "\n",
        "    all_listings = []\n",
        "\n",
        "    async with async_playwright() as p:\n",
        "        browser = await p.chromium.launch(headless=True, args=[\"--no-sandbox\"])\n",
        "        context = await browser.new_context(user_agent=\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) Chrome/120.0.0.0\")\n",
        "        page = await context.new_page()\n",
        "\n",
        "        for area in neighborhoods:\n",
        "            batch = await scrape_neighborhood(page, area)\n",
        "            all_listings.extend(batch)\n",
        "\n",
        "            # Prevents loss if the session times out\n",
        "            if len(all_listings) > 0:\n",
        "                pd.DataFrame(all_listings).drop_duplicates(subset=['url']).to_csv(\"nairobi_master_backup.csv\", index=False)\n",
        "\n",
        "            await asyncio.sleep(2)\n",
        "\n",
        "        await browser.close()\n",
        "\n",
        "    if all_listings:\n",
        "        final_df = pd.DataFrame(all_listings).drop_duplicates(subset=['url'])\n",
        "        filename = f\"raw_listings_{datetime.now().strftime('%Y%m%d')}.csv\"\n",
        "        final_df.to_csv(filename, index=False)\n",
        "        print(f\"\\nSCRAPE COMPLETE! Total Unique Properties: {len(final_df)}\")\n",
        "        from google.colab import files\n",
        "        files.download(filename)\n",
        "    else:\n",
        "        print(\"\\n No data collected. Check internet connection or site availability.\")\n",
        "\n",
        "# Execute the master scraper\n",
        "await run_master_scraper()"
      ]
    }
  ]
}